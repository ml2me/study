{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea6616",
   "metadata": {},
   "source": [
    "### Мыслить инвариантами в контексте написания чистого кода означает: \n",
    "смещение фокуса с того, как код работает в данный момент, на то, каким условиям он должен удовлетворять всегда (до, во время и после своего выполнения).\n",
    "\n",
    "Инвариант (в программировании) — это утверждение или условие, которое остается истинным на протяжении всего времени жизни объекта, функции или целой системы, если только не происходит ошибка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0df0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мода для набора с одной модой: 2 (появляется 2 раз)\n",
      "Моды для набора с двумя модами: 2 (каждая появляется по 2 раз)\n",
      "Мода для категориальных данных: red (появляется 3 раз)\n"
     ]
    }
   ],
   "source": [
    "# вычисление моды в наборе значений. \n",
    "# Мода - статистическая мера центральной тенденции, представляющая собой значение, которое встречается в наборе данных чаще всего. \n",
    "# Не обязательно должна быть уникальной: в одном наборе данных может быть несколько мод или не быть ни одной (если все значения встречаются одинаково часто).\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "# Пример с одной модой\n",
    "data_single_mode = [1, 2, 2, 3, 4]\n",
    "mode_single = stats.mode(data_single_mode)\n",
    "print(f\"Мода для набора с одной модой: {mode_single[0]} (появляется {mode_single[1]} раз)\")\n",
    "\n",
    "# Пример с двумя модами\n",
    "data_bimodal = [1, 2, 2, 3, 3, 4]\n",
    "mode_bimodal = stats.mode(data_bimodal)\n",
    "print(f\"Моды для набора с двумя модами: {mode_bimodal[0]} (каждая появляется по {mode_bimodal[1]} раз)\")\n",
    "\n",
    "# Категориальные данные\n",
    "data_categorical = ['red', 'blue', 'blue', 'green', 'red', 'red']\n",
    "counter = Counter(data_categorical)\n",
    "mode_categorical = counter.most_common(1)[0]  # most_common(1) возвращает список с одной парой (элемент, частота)\n",
    "print(f\"Мода для категориальных данных: {mode_categorical[0]} (появляется {mode_categorical[1]} раз)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025d287",
   "metadata": {},
   "source": [
    "### BERT - отличный выбор для задачи поиска именованных сущностей\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) является отличным и часто используемым выбором для задачи NER (Named Entity Recognition) — распознавания именованных сущностей.\n",
    "\n",
    "1. Контекст с двух сторон (Bidirectional)\n",
    "2. Контекстуализированные эмбеддинги (Word Representations) \n",
    "3. Решение проблемы OOV (Out-of-Vocabulary) BERT использует токенизатор WordPiece (или BPE).\n",
    "\n",
    "###### Архитектура \"Token Classification\"\n",
    "\n",
    "BERT легко адаптируется под NER. Стандартный пайплайн выглядит так:\n",
    "\n",
    "Текст токенизируется в подслова.\n",
    "\n",
    "Каждый токен проходит через BERT и превращается в вектор (скрытое состояние).\n",
    "\n",
    "Поверх BERT вешается простой линейный слой (Full-connected layer) с Softmax, который классифицирует каждый вектор (каждое слово или подслово) в одну из NER-меток (например: B-PER, I-PER, B-LOC, O и т.д.).\n",
    "\n",
    "###### Возможные нюансы (чего стоит опасаться)\n",
    "\n",
    "Хотя BERT отличный выбор, есть несколько моментов, которые нужно учитывать:\n",
    "\n",
    "Длина последовательности: BERT имеет ограничение на длину входных данных (обычно 512 токенов). Для очень длинных документов это может быть проблемой, но для NER на уровне предложений это не критично.\n",
    "\n",
    "Ресурсы: BERT (особенно большие версии вроде BERT-large) требует видеокарты (GPU). Однако для NER обычно хватает маленьких версий (BERT-base или DistilBERT), которые работают быстро и на CPU.\n",
    "\n",
    "Скорость инференса: Для задач реального времени (real-time streaming) BERT может быть медленнее более легких моделей (LSTM + CRF), но современные квантованные версии решают эту проблему.\n",
    "\n",
    "######  Современные последователи вроде RoBERTa, DeBERTa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452fc1cc",
   "metadata": {},
   "source": [
    "### Мера R2\n",
    "Мера R2 (коэффициент детерминации) в sklearn.linear_model.LinearRegression — это статистическая мера, которая показывает, насколько хорошо модель линейной регрессии соответствует данным.\n",
    "\n",
    "В контексте библиотеки sklearn это основная встроенная метрика качества для регрессии, доступная через метод score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbca4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score # отдельная функция для расчета\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Это и есть R^2\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"Коэффициент детерминации: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
